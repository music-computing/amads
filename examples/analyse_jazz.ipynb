{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyzing jazz recordings from the `Jazz-Trio-Database`\n",
    "Author: [Huw Cheston](https://huwcheston.github.io)\n",
    "\n",
    "This notebook walks through a few basic features for analysing rhythm and timing in jazz, using data from the Jazz Trio Database [1]. The predictive modelling aspect is inspired by [2].\n",
    "\n",
    "*References:*\n",
    "\n",
    "[1] Cheston, H., Schlichting, J.L., Cross, I. and Harrison, P.M.C. (2024) Jazz Trio Database:\n",
    "Automated Annotation of Jazz Piano Trio Recordings Processed Using Audio Source Separation.\n",
    "Transactions of the International Society for Music Information Retrieval, 7/1 (pp. 144â€“158).\n",
    "\n",
    "[2] Cheston, H., Schlichting, J. L., Cross, I., & Harrison, P. M. C. (2024). Rhythmic qualities of jazz\n",
    "improvisation predict performer identity and style in source-separated audio recordings. Royal Society\n",
    "Open Science. 11/11."
   ],
   "id": "8d2c9b869ec61b6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import dependencies, set constants",
   "id": "22ab963ee92a9a8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from musmart.timing.swing import beat_upbeat_ratio\n",
    "from musmart.timing.tempo_modeling import tempo_slope, tempo_fluctuation, tempo_drift"
   ],
   "id": "c2a7267c5e02d53b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:01.157331Z",
     "start_time": "2024-12-04T13:10:52.663747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This notebook requires statsmodels to create a predictive model\n",
    "# This is NOT part of the current installation of the package\n",
    "import statsmodels.api as sm"
   ],
   "id": "7cdb879dc84777f9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pull data from JTD\n",
    "\n",
    "We need to download the JTD data first. This consists of multiple recordings, with each recording containing onset timestamps for the piano instrument. \n",
    "\n",
    "These are split into `beats`, which are those onsets which can be matched with a timestamp from an external beat tracker, and `onsets`, which is just every onset regardless of if it can be matched."
   ],
   "id": "c9e593747016f999"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:44:13.184552Z",
     "start_time": "2024-12-04T11:43:54.364785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"https://github.com/HuwCheston/Jazz-Trio-Database/releases/download/v02/jazz-trio-database-v02.zip\" \n",
    "zip_file_path = \"jtd.zip\"\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(zip_file_path, \"wb\") as file:\n",
    "    file.write(response.content)# Ensure it exists\n",
    "# Extract the zip file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"\")"
   ],
   "id": "845d40a6f2846252",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get data from target performers\n",
    "We'll get data for tracks by Bill Evans and Oscar Peterson.\n",
    "\n",
    "For our purposes, we can also split `onsets` into `upbeats`, which are those onsets *not* contained in `beats`."
   ],
   "id": "49b837dec645593e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:01.171260Z",
     "start_time": "2024-12-04T13:11:01.164723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(track_loc: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Given the name of a track, return arrays of piano beats and piano onsets\"\"\"\n",
    "    # Define names of csv files\n",
    "    beats_file = os.path.join(os.getcwd(), 'jazz-trio-database-v02', track_loc, 'beats.csv')\n",
    "    onsets_file = os.path.join(os.getcwd(), 'jazz-trio-database-v02', track_loc, 'piano_onsets.csv')\n",
    "    # Load csv files into numpy arrays\n",
    "    bea = np.genfromtxt(beats_file, delimiter=',')[1:, 2]    # this is the column for piano quarter notes\n",
    "    onse = np.genfromtxt(onsets_file)\n",
    "    # Split `onsets` into `upbeats` (i.e., every onset that doesn't mark a beat)\n",
    "    upbea = onse[~np.isin(onse, bea)]\n",
    "    return upbea, bea"
   ],
   "id": "ece69d8e0faad16b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:05.624005Z",
     "start_time": "2024-12-04T13:11:01.183723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evans_beats, evans_upbeats = [], []\n",
    "peterson_beats, peterson_upbeats = [], []\n",
    "\n",
    "for track_folder in os.listdir('jazz-trio-database-v02'):\n",
    "    metadata_file = os.path.join(os.getcwd(), 'jazz-trio-database-v02', track_folder, 'metadata.json')\n",
    "    if os.path.isfile(metadata_file):\n",
    "        # Load the metadata json and get the name of the pianist\n",
    "        metadata_loaded = json.load(open(metadata_file, 'r'))\n",
    "        pianist = metadata_loaded['musicians']['pianist']\n",
    "        # Load data for the pianists we want\n",
    "        if pianist == \"Bill Evans\" or pianist == \"Oscar Peterson\":\n",
    "            upbeat, beat = load_data(track_folder)\n",
    "            # Append to required list\n",
    "            if pianist == \"Bill Evans\":\n",
    "                evans_beats.append(beat)\n",
    "                evans_upbeats.append(upbeat)\n",
    "            elif pianist == \"Oscar Peterson\":\n",
    "                peterson_beats.append(beat)\n",
    "                peterson_upbeats.append(upbeat)\n"
   ],
   "id": "77211c31ebd0a133",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plot features for a single track\n",
    "\n",
    "Start by extracting beat-upbeat ratio"
   ],
   "id": "30fc628499bbd684"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:05.682498Z",
     "start_time": "2024-12-04T13:11:05.677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Just use a single track\n",
    "desired_beats, desired_upbeats = evans_beats[0], evans_upbeats[0]"
   ],
   "id": "1fce7de6f3073b5b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:05.719502Z",
     "start_time": "2024-12-04T13:11:05.711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate BUR for the first upbeat following each beat\n",
    "burs = beat_upbeat_ratio(\n",
    "    beats=desired_beats, \n",
    "    upbeats=desired_upbeats, \n",
    "    allow_multiple_burs_per_beat=False\n",
    ")\n",
    "# For simplicity, clean BURs between 0.25 and 4.0\n",
    "burs = burs[(burs < 4) & (burs > 0.25)]"
   ],
   "id": "aeab96f5de34feb6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the BURs\n",
    "plt.hist(burs, bins=30)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel='Beat-upbeat ratio', ylabel='Count')\n",
    "plt.show()"
   ],
   "id": "4e7e2091da6589d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Most BURs are around 1.0, but we also have peaks at 2.0 (i.e., \"triplet 8ths\") which is consistent with previous research",
   "id": "57da2283117307fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plot features for several tracks\n",
    "We can plot the distribution of tempo slope values here"
   ],
   "id": "9caf55b141861e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:06.562502Z",
     "start_time": "2024-12-04T13:11:06.142502Z"
    }
   },
   "cell_type": "code",
   "source": "slopes = np.array([tempo_slope(b) for b in evans_beats])",
   "id": "76ff241a2fbf72c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the slopes\n",
    "plt.hist(slopes, bins=30)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel='Tempo slopes (BPM/s)', ylabel='Count')\n",
    "plt.show()"
   ],
   "id": "62a6a1ca1ada09a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results are very clustered around 0 (i.e., no change in tempo), with a slight tendency towards acceleration. Again, this is consistent with previous work.",
   "id": "901cda2071fc7be6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create dataset\n",
    "We're going to extract the following features from each track\n",
    "- Average BUR\n",
    "- Standard deviation BUR\n",
    "- Tempo slope\n",
    "- Tempo drift\n",
    "- Tempo fluctuation\n",
    "\n",
    "and use these to predict whether a track is by Oscar Peterson or Bill Evans"
   ],
   "id": "e04ba54b6fbc3851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:06.961503Z",
     "start_time": "2024-12-04T13:11:06.952001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def construct_features(track_upbeats: np.array, track_beats: np.array) -> np.array:\n",
    "    \"\"\"Given non-beat onsets and beat onsets for a track, construct features\"\"\"\n",
    "    # Calculate BUR for the first upbeat following each beat\n",
    "    burs = beat_upbeat_ratio(\n",
    "        beats=track_beats, \n",
    "        upbeats=track_upbeats, \n",
    "        allow_multiple_burs_per_beat=False\n",
    "    )\n",
    "    # For simplicity, clean BURs between 0.25 and 4.0\n",
    "    burs = burs[(burs < 4) & (burs > 0.25)]\n",
    "    # Get mean and SD BUR\n",
    "    mean_bur, sd_bur = np.nanmean(burs), np.nanstd(burs)\n",
    "    # Get remaining tempo features\n",
    "    slope = tempo_slope(track_beats)\n",
    "    drift = tempo_drift(track_beats)\n",
    "    fluct = tempo_fluctuation(track_beats)\n",
    "    # Create vector of features\n",
    "    return np.array([mean_bur, sd_bur, slope, drift, fluct])\n",
    "    "
   ],
   "id": "52d5b7c24f845932",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:11.672044Z",
     "start_time": "2024-12-04T13:11:07.539505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "performer_upbeats = [evans_upbeats, peterson_upbeats]\n",
    "performer_beats = [evans_beats, peterson_beats]\n",
    "\n",
    "features, targets = [], []\n",
    "# Assign 0 to Evans, 1 to Peterson\n",
    "for perf_idx in range(len(performer_upbeats)):\n",
    "    # Iterate over every track by the current performer\n",
    "    for perf_upbeat, perf_beat in zip(performer_upbeats[perf_idx], performer_beats[perf_idx]):\n",
    "        x_vect = construct_features(perf_upbeat, perf_beat)\n",
    "        # Append everything to lists\n",
    "        features.append(x_vect)\n",
    "        targets.append(perf_idx)    # 0 = Evans, 1 = Peterson\n",
    "# Stack to create arrays for modeling\n",
    "x = np.stack(features)    # (n_tracks, n_features)\n",
    "y = np.array(targets)    # (n_tracks,)\n",
    "assert x.shape[0] == y.shape[0]"
   ],
   "id": "c3ae735471f82a3e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modelling\n",
    "We'll start with creating a simple logistic regression here"
   ],
   "id": "7edc2987ba5dec1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:11.718505Z",
     "start_time": "2024-12-04T13:11:11.707501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale the feature set using z-score\n",
    "x_scale = np.apply_along_axis(stats.zscore, 0, x)\n",
    "# Add a constant term to the model\n",
    "x_const = sm.add_constant(x_scale)"
   ],
   "id": "aeccce121ac08f27",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the model\n",
    "md = sm.Logit(y, x_const).fit()\n",
    "print(md.summary())"
   ],
   "id": "3acd7e0287dcefda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T13:11:11.943999Z",
     "start_time": "2024-12-04T13:11:11.930501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions of training data\n",
    "yhat = md.predict(x_const) \n",
    "prediction = list(map(round, yhat)) \n",
    "# Get accuracy as number of correct predictions\n",
    "acc = sum([pred == actual for pred, actual in zip(prediction, y)]) / len(y)\n",
    "acc"
   ],
   "id": "83f55c79ea4dab8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8176943699731903)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "OK, so we were correct approximately 82% of the times in classifying Oscar Peterson or Bill Evans tracks using these features",
   "id": "eec0ee3676b245d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
